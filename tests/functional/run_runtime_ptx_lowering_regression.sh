#!/usr/bin/env bash
set -euo pipefail

CUMETALC_BIN="$1"
ROOT_DIR="$2"
BUILD_DIR="$3"

if ! command -v xcrun >/dev/null 2>&1; then
  echo "SKIP: xcrun not installed"
  exit 77
fi

if ! xcrun --find metal >/dev/null 2>&1; then
  echo "SKIP: xcrun metal not available"
  exit 77
fi

if ! xcrun --find metallib >/dev/null 2>&1; then
  echo "SKIP: xcrun metallib not available"
  exit 77
fi

WORK_DIR="$(mktemp -d)"
trap 'rm -rf "$WORK_DIR"' EXIT

cat > "${WORK_DIR}/negate.ptx" <<'PTX'
.version 7.0
.target sm_80
.address_size 64

.visible .entry negate(
    .param .u64 param_in,
    .param .u64 param_out
) {
    .reg .f32 %f<2>;
    neg.f32 %f1, %f0;
    ret;
}
PTX

cat > "${WORK_DIR}/reduce_sum.ptx" <<'PTX'
.version 7.0
.target sm_80
.address_size 64

.visible .entry reduce_sum(
    .param .u64 param_in,
    .param .u64 param_out,
    .param .u32 param_n
) {
    .reg .u64 %rd<4>;
    .reg .f32 %f<2>;
    .reg .u32 %r<6>;
    .reg .pred %p<2>;

    ld.param.u64 %rd0, [param_in];
    ld.param.u64 %rd1, [param_out];
    ld.param.u32 %r0,  [param_n];

    mov.u32 %r1, %ctaid.x;
    mov.u32 %r2, %ntid.x;
    mul.lo.u32 %r3, %r1, %r2;
    mov.u32 %r4, %tid.x;
    add.u32 %r3, %r3, %r4;

    setp.ge.u32 %p0, %r3, %r0;
    @%p0 bra DONE;

    cvt.u64.u32 %rd2, %r3;
    shl.b64     %rd2, %rd2, 2;
    add.u64     %rd2, %rd0, %rd2;
    ld.global.f32 %f0, [%rd2];

    atom.global.add.f32 %f1, [%rd1], %f0;

DONE:
    ret;
}
PTX

"${CUMETALC_BIN}" --mode xcrun --input "${WORK_DIR}/negate.ptx" \
  --output "${WORK_DIR}/negate.metallib" --overwrite >/dev/null
"${CUMETALC_BIN}" --mode xcrun --input "${WORK_DIR}/reduce_sum.ptx" \
  --output "${WORK_DIR}/reduce_sum.metallib" --overwrite >/dev/null

cat > "${WORK_DIR}/ptx_lowering_regression.cpp" <<'CPP'
#include "cuda_runtime.h"

#include <cmath>
#include <cstdio>
#include <vector>

namespace {

int run_negate(const char* metallib_path) {
    constexpr int kN = 1024;
    std::vector<float> input(kN);
    std::vector<float> output(kN, 0.0f);
    for (int i = 0; i < kN; ++i) {
        input[static_cast<std::size_t>(i)] = static_cast<float>(i + 1);
    }

    void* d_input = nullptr;
    void* d_output = nullptr;
    if (cudaMalloc(&d_input, sizeof(float) * kN) != cudaSuccess ||
        cudaMalloc(&d_output, sizeof(float) * kN) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: negate cudaMalloc failed\n");
        return 1;
    }

    if (cudaMemcpy(d_input, input.data(), sizeof(float) * kN, cudaMemcpyHostToDevice) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: negate cudaMemcpy HtoD failed\n");
        return 1;
    }

    static const cumetalKernelArgInfo_t kArgInfo[] = {
        {CUMETAL_ARG_BUFFER, 0},
        {CUMETAL_ARG_BUFFER, 0},
    };
    const cumetalKernel_t kernel{
        .metallib_path = metallib_path,
        .kernel_name = "negate",
        .arg_count = 2,
        .arg_info = kArgInfo,
    };

    void* in_arg = d_input;
    void* out_arg = d_output;
    void* args[] = {&in_arg, &out_arg};
    if (cudaLaunchKernel(&kernel, dim3((kN + 255) / 256), dim3(256), args, 0, nullptr) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: negate cudaLaunchKernel failed\n");
        return 1;
    }
    if (cudaDeviceSynchronize() != cudaSuccess) {
        std::fprintf(stderr, "FAIL: negate cudaDeviceSynchronize failed\n");
        return 1;
    }
    if (cudaMemcpy(output.data(), d_output, sizeof(float) * kN, cudaMemcpyDeviceToHost) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: negate cudaMemcpy DtoH failed\n");
        return 1;
    }

    float max_error = 0.0f;
    for (int i = 0; i < kN; ++i) {
        const float expected = -input[static_cast<std::size_t>(i)];
        max_error = fmaxf(max_error, fabsf(output[static_cast<std::size_t>(i)] - expected));
    }
    if (max_error > 1.0e-5f) {
        std::fprintf(stderr, "FAIL: negate max error %e\n", static_cast<double>(max_error));
        return 1;
    }
    return 0;
}

int run_reduce_sum(const char* metallib_path) {
    constexpr int kN = 1 << 14;
    std::vector<float> input(kN, 1.0f);
    const int count = kN;

    void* d_input = nullptr;
    void* d_output = nullptr;
    void* d_count = nullptr;
    if (cudaMalloc(&d_input, sizeof(float) * kN) != cudaSuccess ||
        cudaMalloc(&d_output, sizeof(float)) != cudaSuccess ||
        cudaMalloc(&d_count, sizeof(int)) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: reduce cudaMalloc failed\n");
        return 1;
    }

    if (cudaMemcpy(d_input, input.data(), sizeof(float) * kN, cudaMemcpyHostToDevice) != cudaSuccess ||
        cudaMemcpy(d_count, &count, sizeof(int), cudaMemcpyHostToDevice) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: reduce cudaMemcpy HtoD failed\n");
        return 1;
    }
    if (cudaMemset(d_output, 0, sizeof(float)) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: reduce cudaMemset failed\n");
        return 1;
    }

    static const cumetalKernelArgInfo_t kArgInfo[] = {
        {CUMETAL_ARG_BUFFER, 0},
        {CUMETAL_ARG_BUFFER, 0},
        {CUMETAL_ARG_BUFFER, 0},
    };
    const cumetalKernel_t kernel{
        .metallib_path = metallib_path,
        .kernel_name = "reduce_sum",
        .arg_count = 3,
        .arg_info = kArgInfo,
    };

    void* in_arg = d_input;
    void* out_arg = d_output;
    void* count_arg = d_count;
    void* args[] = {&in_arg, &out_arg, &count_arg};
    if (cudaLaunchKernel(&kernel, dim3((kN + 255) / 256), dim3(256), args, 0, nullptr) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: reduce cudaLaunchKernel failed\n");
        return 1;
    }
    if (cudaDeviceSynchronize() != cudaSuccess) {
        std::fprintf(stderr, "FAIL: reduce cudaDeviceSynchronize failed\n");
        return 1;
    }

    float got = 0.0f;
    if (cudaMemcpy(&got, d_output, sizeof(float), cudaMemcpyDeviceToHost) != cudaSuccess) {
        std::fprintf(stderr, "FAIL: reduce cudaMemcpy DtoH failed\n");
        return 1;
    }
    if (fabsf(got - static_cast<float>(kN)) > 0.5f) {
        std::fprintf(stderr, "FAIL: reduce mismatch got=%f expected=%f\n",
                     static_cast<double>(got),
                     static_cast<double>(kN));
        return 1;
    }
    return 0;
}

}  // namespace

int main(int argc, char** argv) {
    if (argc != 3) {
        std::fprintf(stderr, "usage: %s <negate.metallib> <reduce_sum.metallib>\n", argv[0]);
        return 2;
    }
    if (run_negate(argv[1]) != 0) {
        return 1;
    }
    if (run_reduce_sum(argv[2]) != 0) {
        return 1;
    }
    std::printf("PASS: PTX lowering regression kernels succeeded (negate + reduce_sum)\n");
    return 0;
}
CPP

xcrun clang++ -std=c++20 "${WORK_DIR}/ptx_lowering_regression.cpp" \
  -I"${ROOT_DIR}/runtime/api" \
  -L"${BUILD_DIR}" \
  -Wl,-rpath,"${BUILD_DIR}" \
  -lcumetal \
  -o "${WORK_DIR}/ptx_lowering_regression"

"${WORK_DIR}/ptx_lowering_regression" "${WORK_DIR}/negate.metallib" "${WORK_DIR}/reduce_sum.metallib"
